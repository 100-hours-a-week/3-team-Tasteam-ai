# 모델 비교 분석 및 최종 선택 리포트

**생성 일시**: 2026-01-19  
**분석 대상**: LLM 모델 3개, 임베딩 모델 3개  
**데이터셋**: KR3: Korean Restaurant Reviews with Ratings(https://www.kaggle.com/datasets/ninetyninenewton/kr3-korean-restaurant-reviews-with-ratings)  
**테스트 데이터양**: 음식점 10개, 리뷰 200개(랜덤 샘플링)  
**테스트 환경**: RTX3090
**추론 엔진**: vLLM

---

## 목차

1. [LLM 모델 비교 분석](#1-llm-모델-비교-분석)
2. [임베딩 모델 비교 분석](#2-임베딩-모델-비교-분석)
3. [최종 모델 선택](#3-최종-모델-선택)

---

## 1. LLM 모델 비교 분석

### 1.1 평가 대상 모델

- **Qwen/Qwen2.5-7B-Instruct** (결과 데이터: qwen.json)
- **meta-llama/Llama-3.1-8B-Instruct** (결과 데이터: llama.json)
- **google/gemma-2-9b-it** (결과 데이터: gemma.json)

### 1.2 전체 테스트 통과율

| 모델 | 통과 테스트 | 실패 테스트 | 성공률 |
|------|------------|------------|--------|
| **Qwen2.5-7B-Instruct** | 7/7 | 0/7 | **100.0%** ✅ |
| **Llama-3.1-8B-Instruct** | 6/7 | 1/7 | **85.7%** ⚠️ |
| **gemma-2-9b-it** | 3/7 | 4/7 | **42.9%** ❌ |

**결론**: Qwen이 가장 안정적이며 모든 테스트를 통과했습니다.

### 1.3 성능 지표 비교

#### 1.3.1 감성 분석 (단일)

| 모델 | 평균 (초) | P95 (초) | P99 (초) | 목표 달성 | 처리량 (req/s) |
|------|----------|----------|----------|-----------|----------------|
| **Qwen2.5-7B-Instruct** | **0.843** | **0.874** | **0.874** | ✅ 모두 달성 | 1.19 |
| **Llama-3.1-8B-Instruct** | **0.843** | **0.855** | **0.855** | ✅ 모두 달성 | 1.19 |
| **gemma-2-9b-it** | 8.990 | 21.656 | 21.656 | ❌ 모두 미달 | 0.11 |

**목표값**: 평균 ≤ 1.2초, P95 ≤ 3.2초, P99 ≤ 6.8초

**분석**:
- **Qwen2.5-7B-Instruct과 Llama-3.1-8B-Instruct**: 목표를 모두 달성하며 성능이 거의 동일
- **gemma-2-9b-it**: 목표 대비 약 7-10배 느림, 목표 미달

#### 1.3.2 배치 감성 분석 (10개 레스토랑)

| 모델 | 평균 (초) | 목표 범위 | 목표 달성 | 처리량 (req/s) |
|------|----------|----------|-----------|----------------|
| **Qwen2.5-7B-Instruct** | **9.15** | 5.0-10.0초 | ✅ 달성 | 0.11 |
| **Llama-3.1-8B-Instruct** | 51.67 | 5.0-10.0초 | ❌ 미달 (5배 초과) | 0.02 |
| **gemma-2-9b-it** | 74.66 | 5.0-10.0초 | ❌ 미달 (7배 초과) | 0.01 |

**목표값**: 5.0-10.0초

**분석**:
- **Qwen2.5-7B-Instruct**: 목표 범위 내에서 안정적으로 동작
- **Llama-3.1-8B-Instruct**: 목표 대비 약 5배 느림
- **gemma-2-9b-it**: 목표 대비 약 7배 느림

#### 1.3.3 리뷰 요약

| 모델 | 평균 (초) | P95 (초) | P99 (초) | 목표 달성 | 처리량 (req/s) |
|------|----------|----------|----------|-----------|----------------|
| **Qwen2.5-7B-Instruct** | **0.629** | **0.639** | **0.639** | ✅ 모두 달성 | 1.59 |
| **Llama-3.1-8B-Instruct** | **0.599** | **0.624** | **0.624** | ✅ 모두 달성 | 1.67 |
| **gemma-2-9b-it** | 31.338 | 92.784 | 92.784 | ❌ 모두 미달 | 0.03 |

**목표값**: 평균 ≤ 2.5초, P95 ≤ 4.8초, P99 ≤ 9.5초

**분석**:
- **Qwen2.5-7B-Instruct과 Llama-3.1-8B-Instruct**: 목표를 모두 달성하며 매우 빠름 (목표의 1/4 수준)
- **gemma-2-9b-it**: 목표 대비 약 12-20배 느림, 매우 불안정 (min: 0.61초, max: 92.78초)

#### 1.3.4 배치 리뷰 요약

| 모델 | 상태 | 평균 (초) | 목표 범위 | 목표 달성 |
|------|------|----------|----------|-----------|
| **Qwen2.5-7B-Instruct** | ✅ 통과 | 83.05 | 5.0-10.0초 | ❌ 미달 (8배 초과) |
| **Llama-3.1-8B-Instruct** | ❌ 실패 | - | 5.0-10.0초 | - |
| **gemma-2-9b-it** | ❌ 실패 | - | 5.0-10.0초 | - |

**목표값**: 5.0-10.0초

**분석**:
- **Qwen2.5-7B-Instruct**: 테스트는 통과했으나 목표 범위를 크게 초과 (최적화 필요)
- **Llama-3.1-8B-Instruct와 gemma-2-9b-it**: 테스트 자체가 실패

#### 1.3.5 강점 추출

| 모델 | 상태 | 평균 (초) | P95 (초) | P99 (초) | 목표 달성 |
|------|------|----------|----------|----------|-----------|
| **Qwen2.5-7B-Instruct** | ✅ 통과 | **0.614** | **0.653** | **0.653** | ✅ 모두 달성 |
| **Llama-3.1-8B-Instruct** | ✅ 통과 | **0.611** | **0.668** | **0.668** | ✅ 모두 달성 |
| **gemma-2-9b-it** | ❌ 실패 | - | - | - | - |

**목표값**: 평균 ≤ 3.0초, P95 ≤ 5.5초, P99 ≤ 11.2초

**분석**:
- **Qwen2.5-7B-Instruct*과 Llama-3.1-8B-Instruct**: 목표를 모두 달성하며 매우 빠름 (목표의 1/5 수준)
- **gemma-2-9b-it**: 테스트 실패


**목표값**: 평균 ≤ 1.5초, P95 ≤ 3.0초, P99 ≤ 6.0초

**분석**:
- **Qwen2.5-7B-Instruct과 Llama-3.1-8B-Instruct**: 목표를 모두 달성하며 매우 빠름
- **gemma-2-9b-it**: 테스트 실패

#### 1.3.7 리뷰 이미지 검색

| 모델 | 상태 | 평균 (초) | P95 (초) | P99 (초) | 목표 달성 |
|------|------|----------|----------|----------|-----------|
| **Qwen2.5-7B-Instruct** | ✅ 통과 | **0.614** | **0.649** | **0.649** | ✅ 모두 달성 |
| **Llama-3.1-8B-Instruct** | ✅ 통과 | **0.624** | **0.628** | **0.628** | ✅ 모두 달성 |
| **gemma-2-9b-it** | ❌ 실패 | - | - | - | - |

**목표값**: 평균 ≤ 2.0초, P95 ≤ 4.0초, P99 ≤ 8.0초

**분석**:
- **Qwen2.5-7B-Instruct과 Llama-3.1-8B-Instruct**: 목표를 모두 달성하며 매우 빠름
- **gemma-2-9b-it**: 테스트 실패

### 1.4 목표 달성 요약

| 테스트 항목 | Qwen2.5-7B-Instruct | Llama-3.1-8B-Instruct | gemma-2-9b-it |
|------------|------|-------|-------|
| 감성 분석 (단일) | ✅ | ✅ | ❌ |
| 배치 감성 분석 | ✅ | ❌ | ❌ |
| 리뷰 요약 | ✅ | ✅ | ❌ |
| 배치 리뷰 요약 | ⚠️ (목표 미달) | ❌ (실패) | ❌ (실패) |
| 강점 추출 | ✅ | ✅ | ❌ (실패) |
| 리뷰 이미지 검색 | ✅ | ✅ | ❌ (실패) |

**목표 달성률**:
- **Qwen2.5-7B-Instruct**: 6/7 완전 달성, 1/7 부분 달성 (배치 리뷰 요약은 통과했으나 목표 범위 초과)
- **Llama-3.1-8B-Instruct**: 5/7 완전 달성, 2/7 실패/미달
- **gemma-2-9b-it**: 0/7 완전 달성, 4/7 실패, 3/7 목표 미달

### 1.5 LLM 모델 종합 평가

#### Qwen/Qwen2.5-7B-Instruct
**장점**:
- ✅ 모든 테스트 통과 (100% 성공률)
- ✅ 대부분의 목표 성능 달성
- ✅ 안정적인 성능 (변동성 낮음)
- ✅ 빠른 응답 시간 (대부분 1초 이하)

**단점**:
- ⚠️ 배치 리뷰 요약이 목표 범위 초과 (83초, 목표: 5-10초)

**종합 점수**: ⭐⭐⭐⭐⭐ (5/5)

#### meta-llama/Llama-3.1-8B-Instruct
**장점**:
- ✅ 대부분의 테스트 통과 (85.7% 성공률)
- ✅ 단일 요청 처리 시 Qwen과 유사한 성능
- ✅ 안정적인 성능 (변동성 낮음)

**단점**:
- ❌ 배치 감성 분석 성능 저하 (51초, 목표: 5-10초)
- ❌ 배치 리뷰 요약 테스트 실패

**종합 점수**: ⭐⭐⭐⭐ (4/5)

#### google/gemma-2-9b-it
**장점**:
- 없음

**단점**:
- ❌ 낮은 테스트 통과율 (42.9%)
- ❌ 매우 느린 응답 시간 (목표 대비 7-20배)
- ❌ 불안정한 성능 (변동성 매우 높음)
- ❌ 여러 테스트 실패

**종합 점수**: ⭐ (1/5)

---

## 2. 임베딩 모델 비교 분석

### 2.1 평가 대상 모델

- **jhgan/ko-sbert-multitask** (sbert_results.json)
- **dragonkue/BGE-m3-ko** (drag-bge-m3_results.json)
- **upskyy/bge-m3-korean** (upskyy-bge-m3_results.json)

### 2.2 성능 지표 비교

#### 2.2.1 처리 시간 (Latency)

| 모델 | 평균 (초) | 최소 (초) | 최대 (초) | P95 (초) | 처리량 (req/s) |
|------|----------|----------|----------|----------|----------------|
| **dragonkue/BGE-m3-ko** | **0.037** | **0.034** | **0.044** | **0.044** | **27.34** |
| **upskyy/bge-m3-korean** | 0.039 | 0.036 | 0.043 | 0.043 | 25.92 |
| **jhgan/ko-sbert-multitask** | 0.049 | 0.030 | 0.118 | 0.118 | 20.24 |

**목표값**: 평균 ≤ 1.5초, P95 ≤ 3.0초, P99 ≤ 6.0초

**분석**:
- **모든 모델**: 목표를 크게 달성 (목표의 1/30 수준)
- **dragonkue/BGE-m3-ko**: 가장 빠른 처리 시간 (0.037초)
- **upskyy/bge-m3-korean**: 두 번째로 빠름 (0.039초)
- **jhgan/ko-sbert-multitask**: 가장 느리지만 여전히 매우 빠름 (0.049초)

**성능 순위**: dragonkue/BGE-m3-ko > upskyy/bge-m3-korean > jhgan/ko-sbert-multitask

#### 2.2.2 Precision@k (정확도)

| 모델 | P@1 | P@3 | P@5 | P@10 | 평가 쿼리 수 |
|------|-----|-----|-----|------|-------------|
| **jhgan/ko-sbert-multitask** | **0.125** | **0.083** | **0.050** | **0.063** | 8 |
| **dragonkue/BGE-m3-ko** | **0.125** | **0.083** | **0.050** | **0.050** | 8 |
| **upskyy/bge-m3-korean** | **0.125** | **0.083** | **0.050** | **0.050** | 8 |

**분석**:
- **모든 모델**: Precision@k 값이 동일하거나 매우 유사
- **P@1**: 모든 모델 0.125 (12.5%)
- **P@3**: 모든 모델 0.083 (8.3%)
- **P@5**: 모든 모델 0.050 (5.0%)
- **P@10**: sbert만 0.063 (6.3%), 나머지 0.050 (5.0%)

**정확도 순위**: jhgan/ko-sbert-multitask (P@10에서 약간 우세) > dragonkue/BGE-m3-ko = upskyy/bge-m3-korean

### 2.3 임베딩 모델 종합 평가

#### jhgan/ko-sbert-multitask
**장점**:
- ✅ P@10에서 약간 높은 정확도 (0.063 vs 0.050)
- ✅ 한국어 특화 모델 (ko-sbert)

**단점**:
- ⚠️ 가장 느린 처리 시간 (0.049초, 다른 모델 대비 약 30% 느림)
- ⚠️ 낮은 Precision@k 값 (모든 모델이 낮음)

**종합 점수**: ⭐⭐⭐ (3/5)

#### dragonkue/BGE-m3-ko
**장점**:
- ✅ 가장 빠른 처리 시간 (0.037초)
- ✅ 가장 높은 처리량 (27.34 req/s)
- ✅ 안정적인 성능 (변동성 낮음)

**단점**:
- ⚠️ 낮은 Precision@k 값 (다른 모델과 유사)

**종합 점수**: ⭐⭐⭐⭐ (4/5)

#### upskyy/bge-m3-korean
**장점**:
- ✅ 빠른 처리 시간 (0.039초)
- ✅ 높은 처리량 (25.92 req/s)
- ✅ 안정적인 성능

**단점**:
- ⚠️ 낮은 Precision@k 값 (다른 모델과 유사)

**종합 점수**: ⭐⭐⭐⭐ (4/5)

### 2.4 임베딩 모델 선택 고려사항

**Precision@k 값이 모두 낮은 이유**:
- Ground Truth 데이터의 품질 또는 양 부족 가능성
- 검색 쿼리와 관련 문서 간의 의미적 유사도가 낮을 수 있음
- 모든 모델이 유사한 정확도를 보이므로, 성능(속도)이 더 중요한 선택 기준

**권장사항**:
- **성능 우선**: dragonkue/BGE-m3-ko (가장 빠름)
- **정확도 우선**: jhgan/ko-sbert-multitask (P@10에서 약간 우세, 하지만 차이 미미)

---

## 3. 최종 모델 선택

### 3.1 LLM 모델 선택

**선택 모델**: **Qwen/Qwen2.5-7B-Instruct** ✅

**선택 이유**:
1. **최고의 안정성**: 모든 테스트 통과 (100% 성공률)
2. **우수한 성능**: 대부분의 목표 성능 달성
3. **빠른 응답 시간**: 대부분 1초 이하
4. **낮은 변동성**: 일관된 성능 제공

**대안**: meta-llama/Llama-3.1-8B-Instruct (단일 요청 처리 시 유사한 성능이지만 배치 처리에서 성능 저하)

**제외 모델**: google/gemma-2-9b-it (성능 저하 및 불안정성)

### 3.2 임베딩 모델 선택

**선택 모델**: **dragonkue/BGE-m3-ko** ✅

**선택 이유**:
1. **최고의 성능**: 가장 빠른 처리 시간 (0.037초)
2. **높은 처리량**: 27.34 req/s (다른 모델 대비 약 35% 빠름)
3. **안정적인 성능**: 낮은 변동성
4. **정확도**: 다른 모델과 유사한 Precision@k 값

**대안**: 
- upskyy/bge-m3-korean (성능이 거의 동일)
- jhgan/ko-sbert-multitask (P@10에서 약간 우세하지만 성능 저하)

### 3.3 최종 권장 구성

```
LLM 모델: Qwen/Qwen2.5-7B-Instruct
임베딩 모델: dragonkue/BGE-m3-ko
```

### 3.4 예상 성능

**LLM 작업**:
- 감성 분석: ~0.84초 (목표: ≤1.2초) ✅
- 리뷰 요약: ~0.63초 (목표: ≤2.5초) ✅
- 강점 추출: ~0.61초 (목표: ≤3.0초) ✅

**임베딩 작업**:
- 벡터 검색: ~0.037초 (목표: ≤1.5초) ✅
- 처리량: ~27 req/s

### 3.5 주의사항 및 개선 권장사항

1. **배치 리뷰 요약 최적화 필요**:
   - 현재: 83초 (목표: 5-10초)
   - 최적화 방안: 배치 크기 조정, 병렬 처리 개선

2. **임베딩 모델 Precision@k 개선**:
   - 현재 모든 모델의 Precision@k가 낮음 (0.05-0.125)
   - Ground Truth 데이터 품질 검토 필요
   - 쿼리 확장(Query Expansion) 활용 고려

3. **Gemma 모델 제외**:
   - 성능 및 안정성 문제로 프로덕션 사용 비권장

---

## 부록: 상세 성능 데이터

### A. LLM 모델 상세 성능

#### Qwen/Qwen2.5-7B-Instruct
- 감성 분석: 평균 0.843초, P95 0.874초, 처리량 1.19 req/s
- 배치 감성 분석: 평균 9.15초 (목표: 5-10초)
- 리뷰 요약: 평균 0.629초, P95 0.639초, 처리량 1.59 req/s
- 배치 리뷰 요약: 평균 83.05초 (목표: 5-10초, 최적화 필요)
- 강점 추출: 평균 0.614초, P95 0.653초, 처리량 1.63 req/s
- 리뷰 이미지 검색: 평균 0.614초, P95 0.649초, 처리량 1.63 req/s

#### meta-llama/Llama-3.1-8B-Instruct
- 감성 분석: 평균 0.843초, P95 0.855초, 처리량 1.19 req/s
- 배치 감성 분석: 평균 51.67초 (목표: 5-10초, 미달)
- 리뷰 요약: 평균 0.599초, P95 0.624초, 처리량 1.67 req/s
- 배치 리뷰 요약: 테스트 실패
- 강점 추출: 평균 0.611초, P95 0.668초, 처리량 1.64 req/s
- 리뷰 이미지 검색: 평균 0.624초, P95 0.628초, 처리량 1.60 req/s

#### google/gemma-2-9b-it
- 감성 분석: 평균 8.99초 (목표: ≤1.2초, 미달)
- 배치 감성 분석: 평균 74.66초 (목표: 5-10초, 미달)
- 리뷰 요약: 평균 31.34초 (목표: ≤2.5초, 미달, 변동성 매우 높음)
- 배치 리뷰 요약: 테스트 실패
- 강점 추출: 테스트 실패
- 리뷰 이미지 검색: 테스트 실패

### B. 임베딩 모델 상세 성능

#### jhgan/ko-sbert-multitask
- 처리 시간: 평균 0.049초, P95 0.118초, 처리량 20.24 req/s
- Precision@k: P@1=0.125, P@3=0.083, P@5=0.050, P@10=0.063

#### dragonkue/BGE-m3-ko
- 처리 시간: 평균 0.037초, P95 0.044초, 처리량 27.34 req/s
- Precision@k: P@1=0.125, P@3=0.083, P@5=0.050, P@10=0.050

#### upskyy/bge-m3-korean
- 처리 시간: 평균 0.039초, P95 0.043초, 처리량 25.92 req/s
- Precision@k: P@1=0.125, P@3=0.083, P@5=0.050, P@10=0.050

---

**리포트 작성 완료**: 2026-01-19
