1. sentiment only -> 이때는 중립리뷰를 잘 판단하지 못한다고 생각 (정확히는 긍/부정 한쪽의 리뷰가 아닌데 강한 긍/부정으로 판단하는게 문제라고 생각, 예를 들면, "맛있는데 불친절하다" 를 강한 부정으로 판단. 나는 이건 중립이라고 생각했었음. 또한, 맛있다에 대한 긍정 감성과, 불친절하다의 부정 감성이 둘다 집계되야 한다고 생각.)
2. sentiment + LLM -> 그래서 해당 리뷰들은 분류기 + 가드레일"[는데,지만]"을 통해 LLM이 분류하게 만든다.
3. LLM only -> LLM이 GPU, vllm을 통해 continous batch 같은 걸로 이 방식이 더 빠르게 분류할 것이라고 생각. (속도를 위해 대표벡터 top-k에서 분류하게도 진행(감성분석,요약에 top-k 적용했음)) -> 할루시네이션을 잡기 위한 검증/재시도 지옥 (정확히는 요약, 강점 추출 로직에서 겪었지만, 사실 sentiment 분류도 할루시네이션을 방지할려면 똑같이 분류기,검증/재시도는 필수), 그리고 LLM이 분류기보다 빠를수는 없다.
4. sentiment Only로 전환 -> 예전엔 애매한 리뷰에 대해 긍/부정 스코어 잘 못한다고 생각했지만, 다시 보니 뉘양스를 잘잡아 답을 정확히 내놓는다고 생각.
-> 하지만, 이게 모든 리뷰의 경우를 잘 판단하는건 불가능함.

따라서, 최종 형태
5. 분류기, LLM(분류기적 가드레일로 해결)
    1. 분류기로 분류를 수행한다.

    분류기로 분류를 수행하지만, 데이터에서 딱봐도 애매해서 분류기가 제대로 분류하지 못할만한 리뷰 텍스트들이 LLM 가드레일 대상.
    -> 해당 텍스트와 라벨 부여에 대해서, 이 데이터는 대규모 데이터에서 예외로써 분류되기를 원하는 텍스트를 추출해서 라벨링을 진행한다.

    2. LLM에게 분류기로 분류하기 힘든 리뷰 텍스트와 그에 대한 라벨 정보에 대해 를 LLM에게 컨텍스트로 "이런 이런 리뷰면 이렇게 분류해라" 가드레일 부여

    이제 LLM은 분류기다 그냥 라벨 부여가 더 쉬운 분류기.

    3. 그러니까 원하는 답과 LLM이 내놓은 라벨을 비교해 정확도 산출. LLM이 잘 못하는 분류의 경우에 더 강한 가드레일을 적용하거나, 템플릿을 사용하거나 하라.

