지금 출력된 점수 패턴이 **0.5 → 0.3333 → 0.25 → 0.2 → 0.1667** 이잖아요.

이건 거의 확실하게 “유사도 점수”가 아니라, **RRF(Reciprocal Rank Fusion)의 ‘순위 기반 점수’**가 그대로 나온 겁니다.
수학적으로 딱 **1/(rank+1)** 형태예요:

* rank=1 → 1/2 = **0.5**
* rank=2 → 1/3 = **0.3333**
* rank=3 → 1/4 = **0.25**
* rank=4 → 1/5 = **0.2**
* rank=5 → 1/6 = **0.1667**

즉, 지금 `hit.score`는 “이 문장이 query랑 얼마나 비슷한가”라기보다
**“하이브리드(예: dense + bm25) 결과들을 합쳤을 때 몇 등인가”**에 가까워요.

---

## 왜 이런 일이 생기냐 (핵심)

너 코드가 아마 이런 구조일 가능성이 높아요:

* `query=models.FusionQuery(fusion=models.Fusion.RRF)`
* `prefetch=[ (dense 쿼리), (sparse 쿼리) ]`

RRF는 각 prefetch 결과를 **점수로 섞는 게 아니라 ‘순위’를 섞습니다.**
그래서 최종 점수가 “0.83 vs 0.77” 같은 유사도 느낌이 아니라 **0.5, 0.33…처럼 계단식**으로 나오는 게 정상이에요.

---

## 그럼 지금 결과가 “관련도가 낮아 보이는데” 왜 뜨냐?

RRF는 “각 검색기에서 상위에 나온 것”을 가져오는데,

* `"든든"` 같은 짧은 단어는 **BM25에선 히트가 약하거나(문서에 단어가 없으면 0)**,
* dense 임베딩도 한국어에서 모델/전처리/문장 단위에 따라 **의미 매칭이 약해질 수** 있어요.

그래서 “든든(=푸짐/배부름)”과 직접 관련이 약한 문장도, 각 리스트의 상위에 걸리면 그대로 섞여서 올라옵니다.

---

## 바로 확인해볼 수 있는 진단 2가지

### 1) “진짜 점수”를 보고 싶으면: prefetch를 따로 쏴서 비교

Fusion(RRF) 말고, **dense 단독 / bm25 단독**으로 각각 `query_points` 해서,
각각에서의 score(유사도/매칭)가 어떤지 먼저 확인하는 게 제일 빨라요.

* dense 단독 점수는 보통 cosine/inner-product 기반 “연속값”
* bm25 단독 점수는 sparse 매칭 기반 값

둘 다 약하면 “든든”이 검색어로 너무 짧거나, 모델이 한국어 의미를 잘 못 잡는 상태일 확률이 큽니다.

### 2) RRF의 `k` 값(또는 상수)이 너무 작을 가능성

네 점수 형태가 **정확히 1/(rank+1)** 이라서, RRF의 상수가 사실상 **0 또는 1 수준**처럼 보입니다.
만약 Qdrant의 RRF 구현에서 k(상수)를 조절할 수 있다면(버전/SDK에 따라 다름), 크게 잡으면 점수가 더 촘촘해지긴 하지만…

중요한 건: **어차피 RRF 점수는 “유사도”가 아니라 “순위”**라서, 점수로 품질 판단하면 계속 헷갈립니다.

---

## 품질(“든든”에 맞는 결과) 올리는 실전 처방

### A) 쿼리를 늘려라: 동의어/확장

“든든”은 의미가 넓고 짧아서 약합니다. 아래처럼 확장하면 하이브리드가 훨씬 잘 잡아요.

* “든든한 한 끼”
* “푸짐하다”
* “양이 많다”
* “배부르다”
* “가성비 좋다”

=> 실서비스에선 **쿼리 리라이트(동의어 확장)** 하나만 해도 체감 확 좋아져요.

### B) 한국어 임베딩 모델 점검

만약 dense 쪽이 영어/멀티 모델이거나 한국어 성능이 약하면 “든든=푸짐” 같은 뉘앙스가 잘 안 잡힐 수 있어요.
(특히 리뷰가 구어체/짧은 문장/이모지 섞이면 더)

### C) 2단계 검색(리랭킹) 넣기

하이브리드로 “후보 top-k”만 뽑고,
그 다음에

* cross-encoder rerank
* 또는 LLM rerank(비용은 더 들지만)

이렇게 하면 “최악으로 맛없음” 같은 노이즈가 확 줄어요.

### D) 문서 단위를 너무 길게 넣으면 의미가 퍼짐

지금 3번째 리뷰처럼 아주 긴 문서가 섞여 있죠.
긴 문서 하나에 “든든” 관련 문장이 일부만 있어도 전체가 같이 끌려올 수 있어요.

=> 리뷰를 **문장/절 단위로 쪼개서** 넣으면 “든든(푸짐/배부름)” 관련 구간만 더 잘 떠요.

---

원하면, 네 `query_qdrant_hybrid()` 함수(검색 코드) 붙여주면

1. 지금 점수가 왜 저 식으로 고정되는지 (RRF/파라미터/limit 영향)
2. dense/bm25 각각의 “진짜 score”를 로깅해서 디버깅하는 방법
3. “든든” 같은 감성 키워드에 최적화된 쿼리 확장/리랭킹 구조
   이렇게 **코드 레벨로 바로 개선안** 잡아줄게.
