기존

1. llm과 검증,재시도 가드레일로 정확한 결과 도출해보기

대표 벡터 top_k 리뷰에서 llm이 긍정 리뷰와 부정 리뷰를 뽑고, 그 aspect의 claim이 진짜 리뷰 목록 맞는지에 대해 cos 검증을 수행해서, 통과할 경우에만, 그 리뷰를 사용 했음. llm은 긍정 2개, 부정 1개를 갖고오게함. 그 개수를 충족할 때까지 검증, 재시도를 수행. 재시도가 전부 실패하면 그냥 확보한 것만 가지고감.

-> 첫번째로, top-k에 긍정과 부정이 개수만큼 뽑을 만큼 존재하지 않는다면, llm은 전부 실패때까지 재시도할 것이다.
또한, 그만큼 있더라도, llm이 계속 할루시네이션을 발생시킬수도 있는 법이다.
두번째, llm의 claim이 실제로는 사실 대표벡터 top-k와 비슷하지만, cos 유사도가 낮았다면?
그걸 상정했다 하더라도, 다음 방법은 단어 기반 검증일텐데, 이걸로는 llm이 이 리뷰들을 참조했는지 알기 어렵다.

변경(최종)

2. 고퀄리티의 벡터 서치의 쿼리를 통계로 접근 했다.

llm의 답변에 대해 검증,재시도를 하는 전략은 시간이 매우 많이 드는 전략이었고, 재시도가 전부 실패하는 경우도 빈번했다.

이번에 이렇게 생각했다. LLM이 aspect,claim을 뽑고 그걸 검증,재시도를 하게 하기보다,
이 표본보다 더 큰, 모집단이라고 할만한 집단에서 통계적 정보를 뽑고, 이를 하이브리드 서치의 쿼리로 넣어서 필요한 정보들을 찾는다면, 결국 사람이 직접 서치를 수행한거고, 그 과정 또한, 통계적으로 매우 정확하다. 결과 또한 당연히 매우 정확하고, 개연성 있다.

따라서, 모집단에서 뽑은 통계적 정보를 쿼리로 던져 표본 리뷰에서 recall을 최대한 많이 확보를 진행한다.

kr3의 대규모 리뷰 데이터셋이 존재한다. 이 데이터셋에 대해 빈도 분석을 수행했다.
빈도 분석을 통해 사람들이 리뷰에서 어떤 말을 많이 하는가? 이게 필요했다. 이걸 안다면, 그걸 하이브리드 서치에 그걸 질의한다면, 리뷰에서 유용한 정보를 얻을 수 있을 테니까, 이걸 다시 말하면, 통계적 추정을 이용한거다. 모집단의 통계를 알면, 표본집단의 통계도 비슷할 것이다라는 생각에서 말이다. 즉, 통계적 추정을 사용했다.


처음에 빈도분석을 수행했더니, 조사,어미,많이 쓰지만, 검색 쿼리로써 의미없는 단어(맛있다),동사 어미 변형 등이 많아 전부 불용어를 통해 제거를 수행했다.
그리고, pos-tagging을 통해 명사구인 bigram("직원 친절" 등)만 추출하여 빈도를 추출했다.
그리고. 일반적인 키워드를 게이트 방식으로 사용하여, service, price, food 각각의 카테고리에 bigram들을 분류를 수행했다.

이 bigram의 분포는 상위 빈도의 수는 적고, 중위 빈도는 많고, 하위 빈도도 많은, longtail, 우측꼬리가 긴 분포의 형태였다.

따라서 이 그룹을 지금 이 데이터의 분포가 아닌, 분포의 데이터에 대해서도 적용이 가능하도록

상,중,하 빈도 그룹의 분류를

랭크 기반 비율 컷
상위 0~2% → head
상위 2~20% → mid
상위 20%이상은 -> tail

의 방법을 사용.

우리는, 하이브리드 검색으로 의미있는 정보를 뽑기 위해서니까, 상위 빈도는 무조건 포함 시켰다. 중위 빈도는 가중 샘플링을 통해 선별했고, 하위 빈도는 1개 랜덤 샘플링을 진행해 추가.
--> tail 1개 랜덤 샘플링에 대해서,
tail 1개는 head,mid 쿼리를 중화시키는 역할을 하기도,
head,mid 쿼리만으로는 못찾는 결과를 찾게 할수도 있기 때문이다. 하지만, 왜 랜덤이냐면, 쿼리를 중화시키는 역할만 해도 충분하고, head,mid로는 못찾는 결과를 찾는건, 정확히 말하면, 쿼리 중화의 연장선이다. 그리고, 애초에 head,mid 만으로 못찾는 결과를, 이 tail 때문에 찾을 확률 자체가 굉장히 낮다. 왜냐면, tail은 말그대로, 대규모 데이터에서 빈도가 매우 낮은 데이터들이기 때문이다. 따라서, tail에 어떤 유용한 정보를 찾는데 필요한 정보가 들어 있어 중요 정보를 찾는데 기여 했다기 보다는, 쿼리 중화의 역할을 해서, 결과가 너무 head,mid로만 치우치지 않게 하는 역할을 한다고 보는게 정확하다.

즉, 딥러닝의 data augmentation, bert 사전학습의 10% 랜덤 정답을 넣어 훈련을 시키는 것과 동일한 의도라고 보면 된다.

따라서 결과는 service(head,mid,mid,mid,mid,...,tail)
price(...)
food(...)
등으로 나온다.

이제 이것들 각각을 하이브리드 서치에 쿼리로써 넣는다.

처음에, service,price,food 전부 중복 결과가 많이 나오는 의미 없는 결과가 나오는 상황이 발생함.

따라서, 각 seed에 대해 전처리를 수행함.
service인데 "음식 친절" 같은 단어를 전부 제거.
"직원 친절", "친절 직원"을 제거함.

결과는 더이상 중복 결과가 발생하지 않았다. 중복 문제가 완전히 해결됐다. seed의 의미가 명확하게 나뉘었다는 말이었다.

그리고, 하지만, 전체 리뷰도 처음엔 중복 결과를내놓았지만, 위의 조치를 취하니 중복 결과를 내놓지 않았지만, 단일 레스토랑은 여전히 전처리 전이나 전처리 후나 중복 결과를 내놓았다. 그리고, 무엇보다, 단일 레스토랑이 여러가지 전혀 상관없는 음식을 내놓는 상황이 발생했는데, 이는 그렇다, 내가 그냥 전체 레스토랑 리뷰 데이터에서 내가 임의로 레스토랄을 나눈 데이터이기 때문이다.

따라서, 단일 레스토랑에서 효과가 있는지 판단하기 위해, 직접 판교 '율'이라는 음식점에서 리뷰를 직접 구해 리뷰 데이터셋을 구축했다. 이 데이터셋을 대상으로 적용해보니, 이상한 결과 없이 카테고리 별로 매우 잘 나왔다.

이제 이를 토대로 llm에게 카테고리별 요약과 총요약을 수행시켰다.

그랬더니, 가격에서 얕은 할루시네이션이 발생했다.
가격에 대한 정보가 없는데, 이는 명시하지 않으면서, 그저 llm의 가격 관련 리뷰를 토대로한 가격 측면에서의 해석인, "가성비가 좋다"는 서술을 해버린 것.

따라서 이를 방지하기 위해, 가격 기반 키워드  게이트를 통해, 게이트에 통과되지 못했을 경우, 가격에 대한 언급이 없다면, 가격에 대한 언급이 없다고 할 것이라는 시스템 프롬프트를 주는 것이다.
--> 즉, 현재는 recall을 최대한 올리는 쪽으로 설계했지만, 모델 입장에서 재료가 없지만, 가격 측면에서 요약하라는 지시가 주어졌으면, 모델은 어찌됐든 수행해야하고, 그게 결국 할루시네이션이 된다. 이를 막기 위해 위와 같은 조치를 취했고, 결국에, precision을 높이려는 전략이다.

덕분에, 출력이 모델이 가격에 대한 리뷰는 없지만이라는 본인이 가격을 보고 현재 말을 하는게 아님을 명시해, 다시 말해, 정확한 정보를 제공하게 됐다.

이는 수정 전엔 총 요약에서도 가격에 대한 명시를 안하면서, 가성비가 좋다는 말만 하는, 할루시네이션을 보였지만, 수정 후엔, 가격에 대한 리뷰가 없지만, 가성비가 좋다는 인상이다를 명시해 결과적으로 총 요약에서의 할륏네이션도 없어졌다.

가격 가드레일 전 출력

 "price": {
    "summary": "다양한 메뉴 구성과 알찬 내용물, 좋은 퀄리티로 전반적인 만족도가 높은 가성비를 보인다.",
    "bullets": [
      "덮밥부터 튀김까지 메뉴가 다양하고 퀄리티가 좋아 만족스러운 식사였다",
      "삼겹김치동의 구성과 내용물이 알차다고 평가됐다",
      "점심 시간에 대기 없이 바로 입장해 이용 효율이 좋았다",
      "여러 명이 함께 먹고 모두 만족했다고 평가했다"
    ],

    "overall_summary": {
    "overall_summary": "친절한 응대와 쾌적한 이용 경험 덕분에 동료들과의 식사 장소로 만족도가 높다. 다양한 덮밥과 사이드가 신선하고 완성도가 높아 전반적으로 가성비 좋은 한 끼로 평가된다."

수정 후

"price": {
    "summary": "구체적 금액 언급은 없지만 메뉴 구성이 알차고 품질·비주얼 만족도가 높아 전반적으로 가성비가 좋다는 인상이며, 가격 자체에 대한 언급은 적다.",
    "bullets": [
      "덮밥 종류가 다양하고 오징어튀김 등 사이드까지 구성에 대한 만족도가 높다",
      "메뉴 비주얼과 퀄리티가 좋다는 평가",
      "삼겹김치동이 내용이 알차다는 의견",
      "여러 메뉴를 다시 먹고 싶을 만큼 만족했다"
    ],

"overall_summary": {
    "summary": "친절한 응대와 함께 연어덮밥, 크림카레, 고로케 등 음식의 맛과 퀄리티에 대한 호평이 많다. 가격 숫자 정보는 없지만 구성과 만족도가 높아 가성비가 좋다는 인상이며, 세부적인 가격 정보는 언급이 적다."
  }

모델의 할루시네이션

모델의 할루시네이션은 2가지다.

1. 엄밀한 의미의 할루시네이션

모델은 답변을 위해 없는 사실을 지어낼때 할루시네이션이 발생한다.

즉, 있는 사실을 모델에게 준다면, 모델은 할루시네이션이 발생하지 않는다.

이번 파이프라인에선,

모델에게 리뷰 인덱스를 통해 evidence를 내놓으라는 요구,
요청에 맞는 답변이 불가능할 경우, 지어내지 말고, 사실대로 말하도록 요구로 해결함.



2. 넓은 의미의 할루시네이션

사실을 기반으로 하지만, 데이터에 없는 '추론, 일반화,강조'를 덧붙이는 경우,

이번 파이프라인에서의 예시,

양이 많아서 만족 -> 가성비가 매우 좋다

친절했어요 -> 세심하고 적극적인 응대가 인상적이다

둘다 발생했지만, 치명적이진 않다. 거짓까지는 아니니까.




